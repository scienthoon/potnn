# PoT-NN: ì´ˆì €ì „ë ¥ MCUë¥¼ ìœ„í•œ ê³±ì…ˆ ì—†ëŠ” ì‹ ê²½ë§

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

**PoT-NN**ì€ **ê³±ì…ˆ ì—†ì´ ë”¥ëŸ¬ë‹ ì¶”ë¡ ì´ ê°€ëŠ¥í•œ** ì–‘ìí™” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.  
í•˜ë“œì›¨ì–´ ê³±ì…ˆê¸°ê°€ ì—†ëŠ” ì´ˆì €ê°€ MCU (CH32V003, PY32F003 ë“±)ì—ì„œë„ ì‹ ê²½ë§ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ‡ºğŸ‡¸ [English Documentation](README.md)

## ğŸ¯ í•µì‹¬ íŠ¹ì§•

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ê³±ì…ˆ ì œê±°** | ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ 2ì˜ ê±°ë“­ì œê³±ìœ¼ë¡œ ì–‘ìí™”, `<<`, `>>`, `+` ì—°ì‚°ë§Œ ì‚¬ìš© |
| **ì •ìˆ˜ ì „ìš© ì¶”ë¡ ** | ë¶€ë™ì†Œìˆ˜ì  ì—°ì‚° ì—†ì´ `int8`/`int32`ë§Œ ì‚¬ìš© |
| **5ê°€ì§€ ì¸ì½”ë”©** | ì •í™•ë„ vs ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„ ì„ íƒ ê°€ëŠ¥ |
| **C ì½”ë“œ ìë™ ìƒì„±** | ì˜ì¡´ì„± ì—†ëŠ” ë‹¨ë… ì‹¤í–‰ ê°€ëŠ¥í•œ C í—¤ë” íŒŒì¼ |
| **ë¹„íŠ¸ ì •í™• ì¼ì¹˜** | Python ì‹œë®¬ë ˆì´ì…˜ê³¼ C ì½”ë“œ ì¶œë ¥ 100% ë™ì¼ |

## ğŸ“¦ ì„¤ì¹˜

```bash
pip install potnn
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ë°©ë²• 1: í•œ ì¤„ í•™ìŠµ (ê¶Œì¥)

```python
import torch
import torch.nn as nn
import potnn
from potnn import PoTConv2d, PoTLinear

# 1. PoT ë ˆì´ì–´ë¡œ ëª¨ë¸ ì •ì˜
class TinyNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = PoTConv2d(1, 8, kernel_size=3, padding=1)
        self.conv2 = PoTConv2d(8, 16, kernel_size=3, padding=1)
        self.pool = nn.AdaptiveAvgPool2d(1)  # PoTGlobalAvgPoolë¡œ ìë™ êµì²´ë¨
        self.fc = PoTLinear(16, 10)
    
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = nn.functional.max_pool2d(x, 2)
        x = torch.relu(self.conv2(x))
        x = self.pool(x).view(x.size(0), -1)
        return self.fc(x)

model = TinyNet()

# 2. ì„¤ì •
config = potnn.Config(
    flash=16384,      # íƒ€ê²Ÿ MCU Flash (bytes)
    ram=2048,         # íƒ€ê²Ÿ MCU RAM (bytes)
    mean=0.1307,      # ë°ì´í„°ì…‹ í‰ê· 
    std=0.3081,       # ë°ì´í„°ì…‹ í‘œì¤€í¸ì°¨
    input_h=16, input_w=16, input_channels=1,
)

# 3. í•™ìŠµ (Float â†’ Calibrate â†’ QAT â†’ Integer Sim)
model = potnn.train(model, train_loader, test_loader, config,
                    float_epochs=15, qat_epochs=50)

# 4. C ì½”ë“œ ë³€í™˜
potnn.export(model, "model.h", config)
```

### ë°©ë²• 2: ìˆ˜ë™ íŒŒì´í”„ë¼ì¸

```python
import potnn

# 1ë‹¨ê³„: Float í•™ìŠµ (ì¼ë°˜ PyTorch í•™ìŠµ)
train_float(model, train_loader, epochs=15)

# 2ë‹¨ê³„: BatchNorm í“¨ì „ (ìˆëŠ” ê²½ìš°)
potnn.fuse_batchnorm(model)

# 3ë‹¨ê³„: Activation Scale ë³´ì •
potnn.calibrate(model, train_loader, config)

# 4ë‹¨ê³„: QAT ì¤€ë¹„
potnn.prepare_qat(model, config)

# 5ë‹¨ê³„: QAT í•™ìŠµ
train_qat(model, train_loader, epochs=50)

# 6ë‹¨ê³„: ì •ìˆ˜ ì‹œë®¬ë ˆì´ì…˜ í™œì„±í™” (C í˜¸í™˜)
potnn.enable_integer_sim(model, input_std=config.std, input_mean=config.mean)

# 7ë‹¨ê³„: ë³€í™˜
potnn.export(model, "model.h", config)
```

## ï¿½ ì¸ì½”ë”© ëª¨ë“œ

ì •í™•ë„ vs ë©”ëª¨ë¦¬ íŠ¸ë ˆì´ë“œì˜¤í”„ì— ë”°ë¼ ì„ íƒ:

| ì¸ì½”ë”© | ë ˆë²¨ ìˆ˜ | ê°’ | bit/ê°€ì¤‘ì¹˜ | ìš©ë„ |
|--------|---------|-----|-----------|------|
| `unroll` | 17 | 0, Â±1, Â±2, Â±4, ..., Â±128 | ì½”ë“œ ì–¸ë¡¤ | ìµœê³  ì •í™•ë„ |
| `fp130` | 16 | Â±1, Â±2, Â±4, ..., Â±128 | 4-bit | Dense ë ˆì´ì–´ |
| `5level` | 5 | -8, -1, 0, +1, +8 | 4-bit (skip) | ê· í˜• |
| `2bit` | 4 | -2, -1, +1, +2 | 2-bit | ìµœì†Œ ë©”ëª¨ë¦¬ |
| `ternary` | 3 | -1, 0, +1 | 2-bit (RLE) | í¬ì†Œ ëª¨ë¸ |

### ë ˆì´ì–´ë³„ ì¸ì½”ë”© ì§€ì •

```python
config = potnn.Config(
    flash=16384, ram=2048,
    layer_encodings={
        'conv1': 'unroll',  # ì²« ë ˆì´ì–´: ìµœëŒ€ ì •í™•ë„
        'conv2': '5level',  # ì¤‘ê°„ ë ˆì´ì–´
        'fc': 'unroll',     # ë§ˆì§€ë§‰ ë ˆì´ì–´: ìµœëŒ€ ì •í™•ë„
    },
    default_encoding='5level'
)
```

### ì¸ì½”ë”© ìƒì„¸

#### `unroll` (ê¸°ë³¸ê°’)
- ê°€ì¤‘ì¹˜ë¥¼ ì§ì ‘ shift-add ì—°ì‚°ìœ¼ë¡œ ì–¸ë¡¤
- **Zero ê°€ì¤‘ì¹˜ ìƒëµ** (í¬ì†Œ ëª¨ë¸ì— ìœ ë¦¬)
- ì½”ë“œ í¬ê¸° ê°€ì¥ í¼, ì •í™•ë„ ê°€ì¥ ë†’ìŒ
```c
// ê°€ì¤‘ì¹˜ -8ì¸ ê²½ìš°
acc -= input[i] << 3;  // -8 = -(1<<3)
```

#### `fp130` (FP1.3.0 í¬ë§·)
- 4-bit íŒ¨í‚¹: `[sign(1)][exp(3)]`
- **Zero ì—†ìŒ** (0ì€ Â±1ë¡œ êµëŒ€ ëŒ€ì²´)
- Dense ë ˆì´ì–´ì— ì í•©
```c
// 8ê°œ ê°€ì¤‘ì¹˜ â†’ 1ê°œ uint32
val = (1 << exp) * (sign ? -1 : 1);
```

#### `5level` (Skip ì¸ì½”ë”©)
- 4-bit íŒ¨í‚¹: `[skip(2)][sign(1)][mag(1)]`
- **Skipìœ¼ë¡œ ì—°ì† 0 ì••ì¶•** (0~3ê°œ)
- âš ï¸ **ì œì•½**: 4ê°œ ì´ìƒ ì—°ì† 0 ë¶ˆê°€ (4ë²ˆì§¸ë¶€í„° +1ë¡œ ê°•ì œ ëŒ€ì²´)
```c
skip = (code >> 2) & 0x3;
i += skip;  // 0ë“¤ ê±´ë„ˆë›°ê¸°
val = (mag ? 8 : 1) * (sign ? -1 : 1);
```

#### `2bit`
- 2-bit íŒ¨í‚¹: `[sign(1)][shift(1)]`
- **ìµœì†Œ ë©”ëª¨ë¦¬** (16ê°œ ê°€ì¤‘ì¹˜ â†’ 1ê°œ uint32)
- Zero ì—†ìŒ
```c
shifted = input[i] << (code & 1);  // Ã—1 or Ã—2
acc += (code & 2) ? -shifted : shifted;
```

#### `ternary` (Triple-Run)
- 2-bit ì½”ë“œ + Run-Length ì¸ì½”ë”©
- `11` ì½”ë“œ = ì´ì „ ê°’ 2ë²ˆ ë” ë°˜ë³µ
- ë§¤ìš° í¬ì†Œí•œ ëª¨ë¸ìš©

## ğŸ“ ì§€ì› ë ˆì´ì–´

| ë ˆì´ì–´ | í´ë˜ìŠ¤ | ë¹„ê³  |
|--------|--------|------|
| Conv2D | `PoTConv2d` | ëª¨ë“  í‘œì¤€ íŒŒë¼ë¯¸í„° ì§€ì› |
| Conv1D | `PoTConv1d` | ì‹œê³„ì—´ìš© |
| Depthwise | `PoTDepthwiseConv2d` | MobileNet ìŠ¤íƒ€ì¼ |
| Linear | `PoTLinear` | Fully Connected |
| GAP | ìë™ êµì²´ | `nn.AdaptiveAvgPool2d(1)` â†’ `PoTGlobalAvgPool` |
| Add | `PoTAdd` | Residual ì—°ê²°ìš© |
| BatchNorm | ìë™ í“¨ì „ | ì´ì „ Conv/Linearì— í¡ìˆ˜ë¨ |

## âš™ï¸ API ë ˆí¼ëŸ°ìŠ¤

### `potnn.Config`

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|----------|------|------|------|
| `flash` | int | âœ… | Flash ë©”ëª¨ë¦¬ ì˜ˆì‚° (bytes) |
| `ram` | int | âœ… | RAM ì˜ˆì‚° (bytes) |
| `mean` | float/list | âŒ | ë°ì´í„°ì…‹ í‰ê·  |
| `std` | float/list | âŒ | ë°ì´í„°ì…‹ í‘œì¤€í¸ì°¨ |
| `input_h`, `input_w` | int | âŒ | ì…ë ¥ í¬ê¸° (ê¸°ë³¸: 16Ã—16) |
| `input_channels` | int | âŒ | ì…ë ¥ ì±„ë„ ìˆ˜ (ê¸°ë³¸: 1) |
| `layer_encodings` | dict | âŒ | ë ˆì´ì–´ë³„ ì¸ì½”ë”© ì§€ì • |
| `default_encoding` | str | âŒ | ê¸°ë³¸ ì¸ì½”ë”© (ê¸°ë³¸: 'unroll') |

### ì£¼ìš” í•¨ìˆ˜

```python
potnn.train(model, train_loader, test_loader, config, ...)  # ì „ì²´ íŒŒì´í”„ë¼ì¸
potnn.calibrate(model, data_loader, config)                  # Scale ë³´ì •
potnn.prepare_qat(model, config)                             # QAT ëª¨ë“œ í™œì„±í™”
potnn.enable_integer_sim(model, input_std, input_mean)       # C í˜¸í™˜ ëª¨ë“œ
potnn.export(model, output_path, config)                     # C ì½”ë“œ ìƒì„±
potnn.fuse_batchnorm(model)                                  # BN í“¨ì „
```

## ğŸ§ª ê²€ì¦ ê²°ê³¼

- **ë¹„íŠ¸ ì •í™• ì¼ì¹˜**: Python ì •ìˆ˜ ì‹œë®¬ë ˆì´ì…˜ = C ì¶œë ¥ 100%
- **MNIST**: 97%+ ì •í™•ë„, 12KB ë°”ì´ë„ˆë¦¬
- **100ê°œ ëª¨ë¸ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ ëœë¤ ì•„í‚¤í…ì²˜ì—ì„œ ê²€ì¦ ì™„ë£Œ

## ğŸ“ ë¼ì´ì„ ìŠ¤

**ë“€ì–¼ ë¼ì´ì„ ìŠ¤**: GPL-3.0 + ìƒìš© ë¼ì´ì„ ìŠ¤

| ì‚¬ìš© ìš©ë„ | ë¼ì´ì„ ìŠ¤ |
|-----------|----------|
| ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ | GPL-3.0 (ë¬´ë£Œ) |
| ìƒìš©/ë¹„ê³µê°œ í”„ë¡œì íŠ¸ | ìƒìš© ë¼ì´ì„ ìŠ¤ (ë¬¸ì˜) |

ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ê³ í•˜ì„¸ìš”.

## ğŸ™ ê¸°ì—¬í•˜ê¸°

ì´ í”„ë¡œì íŠ¸ëŠ” ê³ ì¡¸ 1ì¸ ê°œë°œìê°€ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.  
ë¶€ì¡±í•œ ë¶€ë¶„ì´ ë§ê³ , ë²„ê·¸ë‚˜ ê°œì„ í•  ì ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì–´ë–¤ ê¸°ì—¬ë“  ì§„ì‹¬ìœ¼ë¡œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!**
- ğŸ› ë²„ê·¸ ì œë³´
- ğŸ’¡ ê¸°ëŠ¥ ì œì•ˆ
- ğŸ”§ Pull Request
- ğŸ“– ë¬¸ì„œ ê°œì„ 

ì´ìŠˆë‚˜ ì•„ì´ë””ì–´ê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  Issueë‚˜ PRì„ ì—´ì–´ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!

---

**Made with â¤ï¸ for ultra-low-power AI**
